# Simplified simulation of high-energy particle storms

### EduHPC 2018: Peachy assignment

(c) 2018 Arturo Gonzalez-Escribano, Eduardo Rodriguez-Gutiez
Group Trasgo, Universidad de Valladolid (Spain)

--------------------------------------------------------------

This is a version of the assignment customized by [João Lourenço](https://docentes.fct.unl.pt/joao-lourenco),
to be used in the course  of Concurrency and Parallelism at [FCT-NOVA](www.di.fct.unl.pt), 
edition 2020-21.

--------------------------------------------------------------

This project was done by André Monteiro, Bruno Brito and João Martins.

--------------------------------------------------------------

# Running the program

1. Create the executables
   - Go to Src directory and run "make all"

2. Version:
   - 2.1 Sequential version has no changes
     - Usage: %s <size> <storm_1_file> [ <storm_i_file> ] ... 

   - 2.2 OMP version
     - Usage: %s <thread_num> <size> <storm_1_file> [ <storm_i_file> ] ...

--------------------------------------------------------------

# Running our scripts

1. testingScript.sh

	Move the script to the Src directory before executing.

   - Script used to run tests. Adapted from post #73 on piazza by Hugo Lopes. Credits are given in the report.

   - Usage: ./testingScript.sh

     - Note: Before using the script remember to manually set the desired parameters in the code:

       - 1. set the use case test files that will be executed.
         - for TF in 01 02 03 04 05 06 07 08 09

       - 2. Amount of threads
         - THREADS="1 2 4 8 16 32"

       - 3. Amount of runs for each test case
         - NRUNS="5"

2. processResults.py
	
   - This script reads the output file generated by the testingScript.sh, parses it and produces an average and speedup value for each test and thread number combination. 

   - Usage: python3 processResults.py <remove_outliers> <file_name>

     - <remove_outliers> is a boolean determining if the biggest and smallest values are removed from the average calculation

     - <file_name> output file produced by the testingScript.sh

     - Note: Before using the script remember to manually set the desired parameters in the code:

       - 1. "test_num" - Amount of test cases performed
       - 2. "workers" - List with the amount of threads the testingScript.sh ran with
         - workers = [1, 2, 4, 8, 16, 32]
       - 3. "runs" - Amount of runs for each test case

3. validateOMP.sh (this script must be run from the scritps directory)

   - This script runs the sequential execution of the problem, energy_storms_seq. After that it runs the OMP version, energy_storms_omp, and compares its results to the sequential version. If it finds results different from the sequential execution it print an error message and both different results.

   - Usage: ./validateOMP.sh

   - Note: Before using the script remember to manually set the desired parameters in the code:
	 - 1. Manualy set the size of the layer and the test files
	 - 2. Amount of threads. Example: THREADS="1 2 4 8 16 32"

4. wave-gen.py

   - Script used to generate test files. Adapted from post #73 on piazza by David Pereira, credits were given in the report.

   - Usage: python3 <filename> <number particles> <max_position> <max_energy> <optional - mode>

   	 - <filename> python file name

   	 - <number particles> particles in the generated file

   	 - <max_position> of the impact

   	 - <max_energy> of the particle

   	 - <optional - mode> Used to tell the script tendencies locations in the impact zones if specified.

   - Note: direct the output of this script into a file.


--------------------------------------------------------------

# How we ran tests

1. At first we started by testing our solution localy to get an idea of performance.

2. After that we proceeded to choose the right combination of tests to perform in order to gather meaningfull information about our solution. We used some tests provided initially but we also used new test cases created by the group.

3. The results presented in the report are a product of running the selected tests on node 13 of the department's cluster.

